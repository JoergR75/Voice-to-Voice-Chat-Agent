# ğŸ¦™ Llama 3.3 Local AI Voice Agent (AMD ROCm + vLLM)

A fully local, GPU-accelerated AI voice assistant powered by vLLM, Gradio, OpenAI Whisper, and Microsoft Edge TTS â€” running entirely on AMD ROCm hardware.

No cloud. No API keys. Just fast, local inference.

## ğŸš€ Overview

This project builds a sarcastic, voice-enabled AI assistant named Eva, running locally using:

- ğŸ§  LLM: Llama 3.3 8B Instruct (via vLLM)

- ğŸ™ï¸ Speech-to-Text: Whisper (base)

- ğŸ”Š Text-to-Speech: Edge-TTS (AriaNeural voice)

- ğŸŒ UI: Gradio web interface

- âš¡ Inference Engine: vLLM

- ğŸ–¥ï¸ GPU Platform: AMD ROCm

Everything runs 100% locally on an AMD GPU with ROCm support.

## ğŸ§  Features

- ğŸ’¬ Text-based chat

- ğŸ™ï¸ Voice input (microphone â†’ Whisper â†’ LLM)

- ğŸ”Š AI voice responses (Edge-TTS)

- âš¡ High-speed inference with vLLM

- ğŸ§© Custom personality system prompt

- ğŸ–¥ï¸ Fully local GPU execution

- ğŸ” Persistent chat history within session

## ğŸ— Architecture

**Pipeline Flow:**

Microphone â†’ Whisper â†’ Llama 3.3 (vLLM) â†’ Edge-TTS â†’ Audio Playback

**Core Components**

- Model loading via vllm.LLM

- Chat template handling with Hugging Face tokenizer

- Async TTS wrapped for synchronous use

- Gradio Blocks UI with:

- Chatbot display

- Text input

- Microphone input

- Autoplay audio responses

## âš™ï¸ Model Configuration
```python
MODEL_ID = "DavidAU/Llama3.3-8B-Instruct-Thinking-Heretic-Uncensored-Claude-4.5-Opus-High-Reasoning"

SamplingParams(
    max_tokens=128,
    temperature=0.8,
    top_p=0.9
)
```

- Short, sharp responses

- Dry humor personality

- Optimized for speed and responsiveness

## ğŸ–¥ Hardware & Platform

Tested on:

- AMD Radeonâ„¢ AI PRO R9700 (RDNA4)

- ROCm 7.2

- Ubuntu 22.04 / 24.04

- PyTorch 2.11 (Preview)

- vLLM 0.14

Designed specifically for AMD GPU acceleration.

## ğŸš€ Installation

### 1ï¸âƒ£ **Update and install** the Python environment
```bash
sudo apt update
sudo apt install ffmpeg -y
python3 -m pip install --upgrade pip wheel --break-system-packages
python3 -m pip install gradio --break-system-packages
python3 -m pip install git+https://github.com/openai/whisper.git --break-system-packages
python3 -m pip install asyncio --break-system-packages
python3 -m pip install edge-tts --break-system-packages
```

### 2ï¸âƒ£ **Download** the Chat Agent script
```bash
wget https://raw.githubusercontent.com/JoergR75/Voice-to-Voice-Chat-Agent/refs/heads/main/chat_agent_transformers.py
```

### 3ï¸âƒ£ **Run** the Chat Agent
```bash
python3 chat_agent_transformers.py
```

### 4ï¸âƒ£ Launch the Gradio web Agent from another device connected to same network

First, SSH into the web server and forward port **7860**:
```echo
ssh -L 7860:0.0.0.0:7860 ai1@pc1
```
or use the the server IP address
```echo
ssh -L 7860:0.0.0.0:7860 ai1@192.168.178.xxx
```
Now you can open **http://localhost:7860** in your local browser to access the Gradio Web Agent.

<img width="943" height="1262" alt="{41C95E6D-D768-44D1-B856-A1A43B5B96B3}" src="https://github.com/user-attachments/assets/05730fcf-f9e4-4dee-a2a0-2ff7888ec693" />
